{"cells":[{"cell_type":"markdown","metadata":{"id":"fRhaDihszans"},"source":["# Transform and Embed Training Data"]},{"cell_type":"markdown","metadata":{"id":"8YrU-bIKzn1i"},"source":["## Dependencies"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":20869,"status":"ok","timestamp":1717052843054,"user":{"displayName":"Krishanu Datta","userId":"13410719387048945333"},"user_tz":240},"id":"wzvTmXHrzV-M"},"outputs":[],"source":["#!pip install opencv-python\n","import numpy as np\n","import pandas as pd\n","import os\n","from tqdm import tqdm\n","import gzip\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","from google.colab import files\n","\n","import torch\n","import os\n","import cv2\n","from torchvision import transforms, datasets, models\n","from torchvision.models import alexnet, AlexNet_Weights, vgg16, VGG16_Weights, resnet18, ResNet18_Weights\n","from torch.utils.data import DataLoader, SubsetRandomSampler\n","import torch.optim as optim\n","\n","from sklearn.model_selection import train_test_split\n","import shutil"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18603,"status":"ok","timestamp":1717052861641,"user":{"displayName":"Krishanu Datta","userId":"13410719387048945333"},"user_tz":240},"id":"izIJGXvR0Ze5","outputId":"0acf591d-bda2-4efc-978b-b5be2527dac8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/Drive\n"]}],"source":["drive.mount('/content/Drive')"]},{"cell_type":"markdown","metadata":{"id":"LnxnLceJzpqN"},"source":["## Data Pre-processing"]},{"cell_type":"markdown","metadata":{"id":"52yLG4NSP3yn"},"source":["### Extract frames from videos and store in hierarchical folder\n","\n","Only needs to be run twice to extract frames from videos."]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":252,"status":"ok","timestamp":1717052871093,"user":{"displayName":"Krishanu Datta","userId":"13410719387048945333"},"user_tz":240},"id":"J56lwiO_zrGp"},"outputs":[],"source":["def extract_frames_from_all_videos(source_folder, target_folder):\n","\n","    # Create target directories if they don't exist\n","    if not os.path.exists(target_folder):\n","        os.makedirs(target_folder)\n","\n","    videos = [file for file in os.listdir(source_folder) if file.endswith('.MOV')]\n","\n","    for video in videos:\n","        # Extract label from video filename (e.g., '1.MOV' -> '1'), cause they didn't upload in right order\n","        label = os.path.splitext(video)[0]\n","        video_path = os.path.join(source_folder, video)\n","        output_folder = os.path.join(target_folder, f'label_{label}')\n","        extract_frames(video_path, output_folder)\n","\n","def extract_frames(video_path, output_folder):\n","    if not os.path.exists(output_folder):\n","        os.makedirs(output_folder)\n","\n","    cap = cv2.VideoCapture(video_path)\n","    count = 0\n","\n","    while True:\n","        success, frame = cap.read()\n","        if not success:\n","            break\n","\n","        frame_filename = f\"{output_folder}/frame_{count:04d}.jpg\"\n","        cv2.imwrite(frame_filename, frame)\n","        count += 1\n","\n","    cap.release()\n","    print(f\"Extracted {count} frames from {video_path} into {output_folder}\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"executionInfo":{"elapsed":7,"status":"error","timestamp":1717052871402,"user":{"displayName":"Krishanu Datta","userId":"13410719387048945333"},"user_tz":240},"id":"NNAlGShW0U5Y","outputId":"553c6455-cebf-44d4-ab0a-d56099768a3d"},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/Drive/MyDrive/Spring Term/6.8301: Advances in Computer Vision/Final_Project/Unprocessed_Data'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-0521f1567287>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msource_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/Drive/MyDrive/Spring Term/6.8301: Advances in Computer Vision/Final_Project/Unprocessed_Data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtarget_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/Drive/MyDrive/Spring Term/6.8301: Advances in Computer Vision/Final_Project/Processed_Data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mextract_frames_from_all_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-3-82742f3feb83>\u001b[0m in \u001b[0;36mextract_frames_from_all_videos\u001b[0;34m(source_folder, target_folder)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mvideos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_folder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.MOV'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvideo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvideos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Drive/MyDrive/Spring Term/6.8301: Advances in Computer Vision/Final_Project/Unprocessed_Data'"]}],"source":["source_folder = '/content/Drive/MyDrive/Spring Term/6.8301: Advances in Computer Vision/Final_Project/Unprocessed_Data'\n","target_folder = '/content/Drive/MyDrive/Spring Term/6.8301: Advances in Computer Vision/Final_Project/Processed_Data'\n","extract_frames_from_all_videos(source_folder, target_folder)"]},{"cell_type":"markdown","metadata":{"id":"AFERXZeeQG99"},"source":["### Load data, using transforms\n","\n","After extracting frames from the videos, run this to get torch dataloaders with all training, validation, and testing set data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VHY52h02QNN4"},"outputs":[],"source":["data_folder = '/content/Drive/MyDrive/Spring Term/6.8301: Advances in Computer Vision/Final_Project/Processed_Data'\n","test_folder = '/content/Drive/MyDrive/Spring Term/6.8301: Advances in Computer Vision/Final_Project/New_Test_Frames'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xcEiS69wsM2q"},"outputs":[],"source":["data_folder = '/content/Drive/MyDrive/Colab Notebooks/Final_Project/Processed_Data'\n","test_folder = '/content/Drive/MyDrive/Colab Notebooks/Final_Project/Processed_Data'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"no5yxyKbJjj8"},"outputs":[],"source":["# transform function for\n","transform = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","# get training, validation, and testing datasets as dataloaders\n","torch.manual_seed(2024)\n","dataset = datasets.ImageFolder(data_folder, transform=transform)\n","test_data = datasets.ImageFolder(test_folder, transform=transform)\n","\n","targets = [sample[1] for sample in dataset.samples]\n","train_idx, valid_idx, _, _ = train_test_split(\n","    np.arange(len(targets)),  # indices to split\n","    targets,                  # classes to stratify by\n","    test_size=0.2,            # 20% for validation\n","    random_state=42,          # random state for reproducibility\n","    stratify=targets          # stratify by target labels\n",")\n","\n","train_sampler = SubsetRandomSampler(train_idx)\n","valid_sampler = SubsetRandomSampler(valid_idx)\n","\n","train_dataloader = DataLoader(dataset, batch_size=32, sampler=train_sampler)\n","val_dataloader = DataLoader(dataset, batch_size=32, sampler=valid_sampler)\n","test_dataloader = DataLoader(test_data, batch_size=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2BuA95EJUoPd"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"WR2n93XzRnwC"},"source":["## Torch Training Loop, Model Loaders"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hMIcLzKgRTIi"},"outputs":[],"source":["def load_resnet_headless():\n","    # load resnet-18, remove fc layer\n","    model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n","    model = torch.nn.Sequential(*list(model.children())[:-1])\n","\n","    # freeze params (not technically necessary)\n","    for param in model.parameters():\n","        param.requires_grad = False\n","\n","    return model\n","\n","def load_alexnet_headless():\n","    # load alexnet, remove fc layer\n","    model = alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)\n","    model.classifier = torch.nn.Sequential(*list(model.classifier.children())[:-1])\n","\n","    # freeze params (not technically necessary)\n","    for param in model.parameters():\n","        param.requires_grad = False\n","\n","    return model\n","\n","def load_vgg_headless():\n","    #load vgg-16, remove fc layer\n","    model = vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n","    model.classifier = torch.nn.Sequential(*list(model.classifier.children())[:-1])\n","\n","    # freeze params (not technically necessary)\n","    for param in model.parameters():\n","        param.requires_grad = False\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"xSHEuxcOzrya"},"source":["## Extract Embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jj-CbDvwGJb1"},"outputs":[],"source":["def embeddings(dataloader, model):\n","    # function to get embeddings using model\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    features = []\n","    model.eval()\n","    model.to(device)\n","\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for inputs, labels in tqdm(dataloader):\n","            all_labels = all_labels + labels.tolist()\n","            inputs = inputs.to(device)\n","            output = model(inputs)\n","            output = output.view(output.size(0), -1)\n","            features.append(output.cpu())\n","\n","    return torch.cat(features), all_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16102,"status":"ok","timestamp":1715565933315,"user":{"displayName":"Hayden Ratliff","userId":"14261906416208905237"},"user_tz":240},"id":"nAY9Jgp6FpE8","outputId":"6e3b4aaf-8627-4830-b649-9e3bfe273ce0"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 171MB/s]\n","Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n","100%|██████████| 233M/233M [00:05<00:00, 43.3MB/s]\n","Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n","100%|██████████| 528M/528M [00:05<00:00, 94.8MB/s]\n"]}],"source":["# load models\n","resnet18_model = load_resnet_headless()\n","alexnet_model = load_alexnet_headless()\n","vgg16_model = load_vgg_headless()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4273830,"status":"ok","timestamp":1715570275062,"user":{"displayName":"Hayden Ratliff","userId":"14261906416208905237"},"user_tz":240},"id":"FEC_N_goM81s","outputId":"828f18cf-6650-46b9-c71a-634afe0a8650"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 255/255 [1:01:17<00:00, 14.42s/it]\n","100%|██████████| 255/255 [04:10<00:00,  1.02it/s]\n","100%|██████████| 255/255 [04:57<00:00,  1.17s/it]\n"]}],"source":["# get training set embeddings, make tables\n","train_resnet_embeddings, train_resnet_labels = embeddings(train_dataloader, resnet18_model)\n","train_resnet_embeddings_table = pd.DataFrame(train_resnet_embeddings).add_prefix(\"dim_\")\n","train_resnet_embeddings_table[\"label\"] = train_resnet_labels\n","train_resnet_embeddings_table.to_csv(\"resnet_embeddings_train.csv\", index=False)\n","\n","train_alexnet_embeddings, train_alexnet_labels = embeddings(train_dataloader, alexnet_model)\n","train_alexnet_embeddings_table = pd.DataFrame(train_alexnet_embeddings).add_prefix(\"dim_\")\n","train_alexnet_embeddings_table[\"label\"] = train_alexnet_labels\n","train_alexnet_embeddings_table.to_csv(\"alexnet_embeddings_train.csv\", index=False)\n","\n","train_vgg_embeddings, train_vgg_labels = embeddings(train_dataloader, vgg16_model)\n","train_vgg_embeddings_table = pd.DataFrame(train_vgg_embeddings).add_prefix(\"dim_\")\n","train_vgg_embeddings_table[\"label\"] = train_vgg_labels\n","train_vgg_embeddings_table.to_csv(\"vgg_embeddings_train.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1083169,"status":"ok","timestamp":1715571358209,"user":{"displayName":"Hayden Ratliff","userId":"14261906416208905237"},"user_tz":240},"id":"gXbdhPqaM-pf","outputId":"99cf8d5c-e19c-4c9e-eeec-7138fd070cea"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 64/64 [15:33<00:00, 14.59s/it]\n","100%|██████████| 64/64 [01:04<00:00,  1.00s/it]\n","100%|██████████| 64/64 [01:15<00:00,  1.18s/it]\n"]}],"source":["# get validation set embeddings, make tables\n","val_resnet_embeddings, val_resnet_labels = embeddings(val_dataloader, resnet18_model)\n","val_resnet_embeddings_table = pd.DataFrame(val_resnet_embeddings).add_prefix(\"dim_\")\n","val_resnet_embeddings_table[\"label\"] = val_resnet_labels\n","val_resnet_embeddings_table.to_csv(\"resnet_embeddings_val.csv\", index=False)\n","\n","val_alexnet_embeddings, val_alexnet_labels = embeddings(val_dataloader, alexnet_model)\n","val_alexnet_embeddings_table = pd.DataFrame(val_alexnet_embeddings).add_prefix(\"dim_\")\n","val_alexnet_embeddings_table[\"label\"] = val_alexnet_labels\n","val_alexnet_embeddings_table.to_csv(\"alexnet_embeddings_val.csv\", index=False)\n","\n","val_vgg_embeddings, val_vgg_labels = embeddings(val_dataloader, vgg16_model)\n","val_vgg_embeddings_table = pd.DataFrame(val_vgg_embeddings).add_prefix(\"dim_\")\n","val_vgg_embeddings_table[\"label\"] = val_vgg_labels\n","val_vgg_embeddings_table.to_csv(\"vgg_embeddings_val.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":121475,"status":"ok","timestamp":1715457560657,"user":{"displayName":"Hayden Ratliff","userId":"10043313624656518093"},"user_tz":240},"id":"qmgX1dkXJ4Bu","outputId":"244a98de-3d9e-4f9e-c84a-95439d54100e"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 185/185 [00:41<00:00,  4.51it/s]\n","100%|██████████| 185/185 [00:37<00:00,  4.95it/s]\n","100%|██████████| 185/185 [00:42<00:00,  4.32it/s]\n"]}],"source":["# get test set embeddings, make tables\n","test_resnet_embeddings, test_resnet_labels = embeddings(test_dataloader, resnet18_model)\n","test_resnet_embeddings_table = pd.DataFrame(test_resnet_embeddings).add_prefix(\"dim_\")\n","test_resnet_embeddings_table[\"label\"] = test_resnet_labels\n","test_resnet_embeddings_table.to_csv(\"resnet_embeddings_test.csv\", index=False)\n","\n","test_alexnet_embeddings, test_alexnet_labels = embeddings(test_dataloader, alexnet_model)\n","test_alexnet_embeddings_table = pd.DataFrame(test_alexnet_embeddings).add_prefix(\"dim_\")\n","test_alexnet_embeddings_table[\"label\"] = test_alexnet_labels\n","test_alexnet_embeddings_table.to_csv(\"alexnet_embeddings_test.csv\", index=False)\n","\n","test_vgg_embeddings, test_vgg_labels = embeddings(test_dataloader, vgg16_model)\n","test_vgg_embeddings_table = pd.DataFrame(test_vgg_embeddings).add_prefix(\"dim_\")\n","test_vgg_embeddings_table[\"label\"] = test_vgg_labels\n","test_vgg_embeddings_table.to_csv(\"vgg_embeddings_test.csv\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"EnFYvaGfY8rl"},"source":["After running the above files, I downloaded all .csv files and then manually compressed them on my local machine. Finally, I uploaded them to GitHub."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":234,"status":"ok","timestamp":1715571999191,"user":{"displayName":"Hayden Ratliff","userId":"14261906416208905237"},"user_tz":240},"id":"y1me3mtUDli7","outputId":"41154a63-4807-48d2-fe3c-aef724c146f1"},"outputs":[{"data":{"application/javascript":"\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"download(\"download_252c13e3-87e9-431c-9a7c-9bd098d5cc32\", \"vgg_embeddings_train.csv\", 191653784)","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"download(\"download_35ea8650-8e36-4424-8abb-9628e172f29b\", \"vgg_embeddings_val.csv\", 47947015)","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"download(\"download_c0121d8c-bc8d-4312-b927-be92718e09a5\", \"alexnet_embeddings_val.csv\", 40994041)","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["files.download(\"vgg_embeddings_train.csv\")\n","files.download(\"vgg_embeddings_val.csv\")\n","files.download(\"alexnet_embeddings_val.csv\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["LnxnLceJzpqN","52yLG4NSP3yn","AFERXZeeQG99","xSHEuxcOzrya"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
